import numpy as np
import cv2
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import time
import json
import threading
import queue
from collections import deque
from pathlib import Path

from kafka_util import consumers, producers
import os

class OptimizedSingleDetector: 
    def __init__(self, class_names_path=None, conf_threshold=0.25, iou_threshold=0.45,
                 app_batch_size=None, max_wait_time=0.05):
        """
        Args:
            app_batch_size: Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î†àÎ≤® Î∞∞Ïπò ÌÅ¨Í∏∞ (NoneÏù¥Î©¥ ÏóîÏßÑ Î∞∞Ïπò ÌÅ¨Í∏∞ ÏÇ¨Ïö©)
            max_wait_time: ÏµúÎåÄ ÎåÄÍ∏∞ ÏãúÍ∞Ñ (Ï¥à)
        """
        # Kafka ÏÑ§Ï†ï
        self.frame_consumer = consumers.FrameConsumer()
        self.result_producer = producers.DetectedResultProducer()
        
        # Î™®Îç∏ ÏÑ§Ï†ï
        self.engine_path = os.getenv('ENGINE_PATH')
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.max_wait_time = max_wait_time
        
        # ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Î°úÎìú
        self.class_names = self._load_class_names(class_names_path)
        self.colors = np.random.uniform(0, 255, size=(len(self.class_names), 3))
        
        # TensorRT ÏóîÏßÑ Î°úÎìú
        self.logger = trt.Logger(trt.Logger.WARNING)
        self.engine = self._load_engine()
        self.context = self.engine.create_execution_context()
        
        # ÏóîÏßÑÏùò Ïã§Ï†ú Î∞∞Ïπò ÌÅ¨Í∏∞ ÌôïÏù∏
        self.engine_batch_size, self.input_shape = self._get_engine_info()
        
        # Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ïπò ÌÅ¨Í∏∞ Í≤∞Ï†ï
        if app_batch_size is None:
            self.app_batch_size = self.engine_batch_size
        else:
            self.app_batch_size = min(app_batch_size, self.engine_batch_size)
        
        # Î≤ÑÌçº Ìï†Îãπ
        self._setup_buffers()
        
        # ÌîÑÎ†àÏûÑ ÌÅê
        self.frame_queue = queue.Queue(maxsize=self.app_batch_size * 4)
        self.processing_thread = None
        self.stop_event = threading.Event()
        
        # ÌÜµÍ≥Ñ
        self.stats = {
            'total_frames': 0,
            'total_inferences': 0,
            'total_inference_time': 0,
            'lock': threading.Lock()
        }
        
        print(f"‚úÖ ÏµúÏ†ÅÌôîÎêú Detector Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        print(f"   - ÏóîÏßÑ Î∞∞Ïπò ÌÅ¨Í∏∞: {self.engine_batch_size}")
        print(f"   - Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ïπò ÌÅ¨Í∏∞: {self.app_batch_size}")
        print(f"   - ÏûÖÎ†• ÌòïÌÉú: {self.input_shape}")
        print(f"   - ÏµúÎåÄ ÎåÄÍ∏∞ ÏãúÍ∞Ñ: {max_wait_time*1000:.1f}ms")
    
    def _load_class_names(self, class_names_path):
        """ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Î°úÎìú"""
        if class_names_path and Path(class_names_path).exists():
            try:
                with open(class_names_path, 'r', encoding='utf-8') as f:
                    if class_names_path.endswith('.json'):
                        data = json.load(f)
                        return data.get('names', list(data.values()))
                    else:
                        return [line.strip() for line in f.readlines() if line.strip()]
            except Exception as e:
                print(f"‚ö†Ô∏è  ÌÅ¥ÎûòÏä§ ÌååÏùº Î°úÎìú Ïã§Ìå®: {e}")
        
        return [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
            'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
            'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
    
    def _load_engine(self):
        """TensorRT ÏóîÏßÑ Î°úÎìú"""
        try:
            with open(self.engine_path, 'rb') as f, trt.Runtime(self.logger) as runtime:
                engine = runtime.deserialize_cuda_engine(f.read())
            print(f"‚úÖ TensorRT ÏóîÏßÑ Î°úÎìú ÏôÑÎ£å: {self.engine_path}")
            return engine
        except Exception as e:
            print(f"‚ùå ÏóîÏßÑ Î°úÎìú Ïã§Ìå®: {e}")
            raise
    
    def _get_engine_info(self):
        """ÏóîÏßÑÏùò Ïã§Ï†ú Î∞∞Ïπò ÌÅ¨Í∏∞ÏôÄ ÏûÖÎ†• ÌòïÌÉú ÌôïÏù∏"""
        if hasattr(self.engine, 'num_io_tensors'):
            # TensorRT 8.5+ API
            for i in range(self.engine.num_io_tensors):
                tensor_name = self.engine.get_tensor_name(i)
                if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                    shape = self.context.get_tensor_shape(tensor_name)
                    batch_size = shape[0] if shape[0] > 0 else 1  # -1Ïù¥Î©¥ ÎèôÏ†Å, ÏñëÏàòÎ©¥ Í≥†Ï†ï
                    return batch_size, shape
        else:
            # TensorRT 7.x/8.x API
            for binding in self.engine:
                if self.engine.binding_is_input(binding):
                    shape = self.context.get_binding_shape(binding)
                    batch_size = shape[0] if shape[0] > 0 else 1
                    return batch_size, shape
        
        return 1, None  # Í∏∞Î≥∏Í∞í
    
    def _setup_buffers(self):
        """GPU Î≤ÑÌçº ÏÑ§Ï†ï"""
        self.inputs = []
        self.outputs = []
        self.bindings = []
        self.stream = cuda.Stream()
        
        if hasattr(self.engine, 'num_io_tensors'):
            for i in range(self.engine.num_io_tensors):
                tensor_name = self.engine.get_tensor_name(i)
                dtype = trt.nptype(self.engine.get_tensor_dtype(tensor_name))
                
                if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                    shape = self.input_shape
                    size = trt.volume(shape) if shape[0] > 0 else trt.volume(shape[1:]) * self.engine_batch_size
                    
                    host_mem = cuda.pagelocked_empty(size, dtype)
                    device_mem = cuda.mem_alloc(host_mem.nbytes)
                    self.bindings.append(int(device_mem))
                    self.inputs.append({'host': host_mem, 'device': device_mem, 
                                      'shape': shape, 'name': tensor_name})
                    self.input_name = tensor_name
                else:
                    shape = self.context.get_tensor_shape(tensor_name)
                    # Ï∂úÎ†• ÌÅ¨Í∏∞ Í≥ÑÏÇ∞ (Î∞∞Ïπò ÌÅ¨Í∏∞ Í≥†Î†§)
                    if shape[0] <= 0:  # ÎèôÏ†Å Î∞∞Ïπò
                        actual_shape = (self.engine_batch_size,) + shape[1:]
                        size = trt.volume(actual_shape)
                    else:
                        size = trt.volume(shape)
                        actual_shape = shape
                    
                    host_mem = cuda.pagelocked_empty(size, dtype)
                    device_mem = cuda.mem_alloc(host_mem.nbytes)
                    self.bindings.append(int(device_mem))
                    self.outputs.append({'host': host_mem, 'device': device_mem, 
                                       'shape': actual_shape, 'name': tensor_name})
                    self.output_name = tensor_name
        
        print(f"üîß Î≤ÑÌçº ÏÑ§Ï†ï ÏôÑÎ£å:")
        print(f"   - ÏûÖÎ†• Î≤ÑÌçº ÌÅ¨Í∏∞: {self.inputs[0]['host'].nbytes / 1024 / 1024:.1f} MB")
        print(f"   - Ï∂úÎ†• Î≤ÑÌçº ÌÅ¨Í∏∞: {self.outputs[0]['host'].nbytes / 1024 / 1024:.1f} MB")
    
    def preprocess_images(self, images):
        """Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (Î∞∞Ïπò ÎòêÎäî Îã®Ïùº)"""
        if self.engine_batch_size == 1:
            # ÏóîÏßÑÏù¥ Îã®Ïùº Î∞∞ÏπòÎßå ÏßÄÏõêÌïòÎäî Í≤ΩÏö∞
            return self._preprocess_single_batch(images)
        else:
            # ÏóîÏßÑÏù¥ ÏßÑÏßú Î∞∞ÏπòÎ•º ÏßÄÏõêÌïòÎäî Í≤ΩÏö∞
            return self._preprocess_true_batch(images)
    
    def _preprocess_single_batch(self, images):
        """Îã®Ïùº Ïù¥ÎØ∏ÏßÄÏî© Ï†ÑÏ≤òÎ¶¨ (ÏóîÏßÑ Î∞∞Ïπò ÌÅ¨Í∏∞ = 1)"""
        preprocessed = []
        metadata = []
        
        _, input_h, input_w = self.input_shape[1], self.input_shape[2], self.input_shape[3]
        
        for image in images:
            img_h, img_w = image.shape[:2]
            scale = min(input_w / img_w, input_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            padded = np.full((input_h, input_w, 3), 114, dtype=np.uint8)
            pad_x = (input_w - new_w) // 2
            pad_y = (input_h - new_h) // 2
            padded[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized
            
            tensor = padded.astype(np.float32) / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))
            tensor = np.expand_dims(tensor, axis=0)  # [1, 3, H, W]
            
            preprocessed.append(tensor)
            metadata.append({'scale': scale, 'pad_x': pad_x, 'pad_y': pad_y})
        
        return preprocessed, metadata
    
    def _preprocess_true_batch(self, images):
        """ÏßÑÏßú Î∞∞Ïπò Ï†ÑÏ≤òÎ¶¨ (ÏóîÏßÑÏù¥ Î∞∞Ïπò ÏßÄÏõê)"""
        batch_tensors = []
        metadata = []
        
        _, input_h, input_w = self.input_shape[1], self.input_shape[2], self.input_shape[3]
        
        for image in images:
            img_h, img_w = image.shape[:2]
            scale = min(input_w / img_w, input_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            padded = np.full((input_h, input_w, 3), 114, dtype=np.uint8)
            pad_x = (input_w - new_w) // 2
            pad_y = (input_h - new_h) // 2
            padded[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized
            
            tensor = padded.astype(np.float32) / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))
            
            batch_tensors.append(tensor)
            metadata.append({'scale': scale, 'pad_x': pad_x, 'pad_y': pad_y})
        
        # ÏßÑÏßú Î∞∞ÏπòÎ°ú Í≤∞Ìï©
        batch_tensor = np.stack(batch_tensors, axis=0)  # [N, 3, H, W]
        
        # ÏóîÏßÑ Î∞∞Ïπò ÌÅ¨Í∏∞Ïóê ÎßûÏ∂∞ Ìå®Îî©
        if len(batch_tensors) < self.engine_batch_size:
            padding_count = self.engine_batch_size - len(batch_tensors)
            padding = np.zeros((padding_count,) + batch_tensor.shape[1:], dtype=np.float32)
            batch_tensor = np.concatenate([batch_tensor, padding], axis=0)
        
        return batch_tensor, metadata
    
    def postprocess_results(self, outputs, metadata_list, actual_batch_size):
        """ÌõÑÏ≤òÎ¶¨ Í≤∞Í≥º"""
        results = []
        
        if self.engine_batch_size == 1:
            # Îã®Ïùº Ï∂îÎ°† Í≤∞Í≥ºÎì§
            for i, (output, metadata) in enumerate(zip(outputs, metadata_list)):
                boxes, scores, class_ids = self._postprocess_single(output, metadata)
                results.append((boxes, scores, class_ids))
        else:
            # ÏßÑÏßú Î∞∞Ïπò Í≤∞Í≥º
            batch_output = outputs[0]  # [batch_size, ...]
            for i in range(actual_batch_size):
                single_output = batch_output[i]  # iÎ≤àÏß∏ Ïù¥ÎØ∏ÏßÄ Í≤∞Í≥º
                metadata = metadata_list[i]
                boxes, scores, class_ids = self._postprocess_single(single_output, metadata)
                results.append((boxes, scores, class_ids))
        
        return results
    
    def _postprocess_single(self, output, metadata):
        """Îã®Ïùº Ïù¥ÎØ∏ÏßÄ ÌõÑÏ≤òÎ¶¨"""
        if len(output.shape) == 3:
            output = output[0]
        if len(output.shape) == 2 and output.shape[0] < output.shape[1]:
            output = output.T
        
        x_centers = output[:, 0]
        y_centers = output[:, 1]
        widths = output[:, 2]
        heights = output[:, 3]
        class_confs = output[:, 4:]
        
        max_confs = np.max(class_confs, axis=1)
        class_ids = np.argmax(class_confs, axis=1)
        
        valid_mask = max_confs > self.conf_threshold
        if not np.any(valid_mask):
            return np.array([]), np.array([]), np.array([])
        
        # Ï¢åÌëú Î≥ÄÌôò
        scale = metadata['scale']
        pad_x = metadata['pad_x']
        pad_y = metadata['pad_y']
        
        x_centers = (x_centers[valid_mask] - pad_x) / scale
        y_centers = (y_centers[valid_mask] - pad_y) / scale
        widths = widths[valid_mask] / scale
        heights = heights[valid_mask] / scale
        max_confs = max_confs[valid_mask]
        class_ids = class_ids[valid_mask]
        
        x1s = x_centers - widths / 2
        y1s = y_centers - heights / 2
        boxes = np.column_stack([x1s, y1s, widths, heights])
        
        # NMS
        if len(boxes) > 0:
            indices = cv2.dnn.NMSBoxes(boxes.tolist(), max_confs.tolist(),
                                      self.conf_threshold, self.iou_threshold)
            if len(indices) > 0:
                if isinstance(indices, tuple):
                    indices = indices[0] if len(indices) > 0 else []
                if len(indices) > 0:
                    indices = indices.flatten() if hasattr(indices, 'flatten') else indices
                    return boxes[indices], max_confs[indices], class_ids[indices]
        
        return np.array([]), np.array([]), np.array([])
    
    def infer_batch(self, images, camera_ids):
        """Î∞∞Ïπò Ï∂îÎ°† Ïã§Ìñâ"""
        if not images:
            return []
        
        actual_batch_size = len(images)
        start_time = time.time()
        
        # Ï†ÑÏ≤òÎ¶¨
        preprocessed, metadata = self.preprocess_images(images)
        
        if self.engine_batch_size == 1:
            # ÏóîÏßÑÏù¥ Îã®Ïùº Î∞∞ÏπòÎßå ÏßÄÏõê - ÏàúÏ∞® Ïã§Ìñâ
            all_outputs = []
            for tensor in preprocessed:
                np.copyto(self.inputs[0]['host'], tensor.ravel())
                cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
                
                # ÎèôÏ†Å ÌòïÌÉú ÏÑ§Ï†ï (ÌïÑÏöîÏãú)
                if hasattr(self.context, 'set_tensor_shape'):
                    self.context.set_tensor_shape(self.input_name, tensor.shape)
                
                # Ï∂îÎ°† Ïã§Ìñâ
                if hasattr(self.context, 'execute_async_v3'):
                    self.context.set_tensor_address(self.input_name, self.inputs[0]['device'])
                    self.context.set_tensor_address(self.output_name, self.outputs[0]['device'])
                    self.context.execute_async_v3(stream_handle=self.stream.handle)
                else:
                    self.context.execute_v2(bindings=self.bindings)
                
                # Í≤∞Í≥º Î≥µÏÇ¨
                cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
                self.stream.synchronize()
                
                # Ï∂úÎ†• Ï†ÄÏû•
                output_data = self.outputs[0]['host'].reshape(self.outputs[0]['shape'])
                all_outputs.append(output_data)
        else:
            # ÏóîÏßÑÏù¥ ÏßÑÏßú Î∞∞Ïπò ÏßÄÏõê - ÌïúÎ≤àÏóê Ïã§Ìñâ
            batch_tensor = preprocessed
            np.copyto(self.inputs[0]['host'], batch_tensor.ravel())
            cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
            
            # ÎèôÏ†Å ÌòïÌÉú ÏÑ§Ï†ï
            if hasattr(self.context, 'set_tensor_shape'):
                self.context.set_tensor_shape(self.input_name, batch_tensor.shape)
            
            # Ï∂îÎ°† Ïã§Ìñâ
            if hasattr(self.context, 'execute_async_v3'):
                self.context.set_tensor_address(self.input_name, self.inputs[0]['device'])
                self.context.set_tensor_address(self.output_name, self.outputs[0]['device'])
                self.context.execute_async_v3(stream_handle=self.stream.handle)
            else:
                self.context.execute_v2(bindings=self.bindings)
            
            # Í≤∞Í≥º Î≥µÏÇ¨
            cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
            self.stream.synchronize()
            
            all_outputs = [self.outputs[0]['host'].reshape(self.outputs[0]['shape'])]
        
        inference_time = time.time() - start_time
        
        # ÌõÑÏ≤òÎ¶¨
        results = self.postprocess_results(all_outputs, metadata, actual_batch_size)
        
        # Kafka Í≤∞Í≥º Ï†ÑÏÜ°
        for i, (camera_id, (boxes, scores, class_ids)) in enumerate(zip(camera_ids, results)):
            detections = []
            for box, score, class_id in zip(boxes, scores, class_ids):
                x1, y1, w, h = box.astype(int)
                detections.append({
                    'bbox': [float(x1), float(y1), float(w), float(h)],
                    'confidence': float(score),
                    'class': int(class_id),
                    'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                })
            
            payload = {
                'camera_id': camera_id,
                'timestamp': time.time(),
                'detections': detections,
                'inference_time_ms': inference_time * 1000,
                'batch_size': actual_batch_size,
                'engine_batch_size': self.engine_batch_size
            }
            
            payload_bytes = json.dumps(payload).encode('utf-8')
            self.result_producer.send_message(
                key=camera_id.encode('utf-8'),
                value=payload_bytes
            )
        
        # ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
        with self.stats['lock']:
            self.stats['total_frames'] += actual_batch_size
            self.stats['total_inferences'] += 1
            self.stats['total_inference_time'] += inference_time
        
        return results
    
    def batch_processor(self):
        """Î∞∞Ïπò Ï≤òÎ¶¨ ÏõåÏª§"""
        batch_buffer = []
        last_process_time = time.time()
        
        while not self.stop_event.is_set():
            try:
                timeout = max(0.001, self.max_wait_time - (time.time() - last_process_time))
                
                try:
                    item = self.frame_queue.get(timeout=timeout)
                    if item is None:
                        break
                    batch_buffer.append(item)
                except queue.Empty:
                    pass
                
                # Ï≤òÎ¶¨ Ï°∞Í±¥
                should_process = (
                    len(batch_buffer) >= self.app_batch_size or
                    (len(batch_buffer) > 0 and 
                     time.time() - last_process_time >= self.max_wait_time)
                )
                
                if should_process and batch_buffer:
                    camera_ids, images = zip(*batch_buffer)
                    self.infer_batch(list(images), list(camera_ids))
                    self.result_producer.flush()
                    
                    batch_buffer.clear()
                    last_process_time = time.time()
                    
            except Exception as e:
                print(f"‚ùå Î∞∞Ïπò Ï≤òÎ¶¨ Ïò§Î•ò: {e}")
                batch_buffer.clear()
    
    def run(self):
        """Î©îÏù∏ Ïã§Ìñâ"""
        print(f"üöÄ ÏµúÏ†ÅÌôîÎêú Í≤ÄÏ∂ú ÏãúÏûë")
        
        self.processing_thread = threading.Thread(target=self.batch_processor)
        self.processing_thread.start()
        
        try:
            for msg in self.frame_consumer.consumer:
                if self.stop_event.is_set():
                    break
                
                camera_id = msg.key.decode('utf-8')
                frame_bytes = msg.value
                
                try:
                    arr = np.frombuffer(frame_bytes, dtype=np.uint8)
                    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
                    if frame is None:
                        continue
                    
                    if not self.frame_queue.full():
                        self.frame_queue.put((camera_id, frame), block=False)
                    else:
                        print(f"‚ö†Ô∏è ÌÅê Ìè¨Ìôî - {camera_id} ÌîÑÎ†àÏûÑ ÎìúÎ°≠")
                        
                except Exception as e:
                    print(f"‚ùå ÌîÑÎ†àÏûÑ Ï≤òÎ¶¨ Ïò§Î•ò {camera_id}: {e}")
                
                if self.stats['total_frames'] % 50 == 0:
                    self.print_stats()
                    
        except KeyboardInterrupt:
            print("\nüõë Ï¢ÖÎ£å")
        finally:
            self.stop_event.set()
            self.frame_queue.put(None)
            if self.processing_thread:
                self.processing_thread.join()
            self.result_producer.producer.flush()
            self.print_stats()
    
    def print_stats(self):
        """ÌÜµÍ≥Ñ Ï∂úÎ†•"""
        with self.stats['lock']:
            if self.stats['total_inferences'] > 0:
                avg_inference_time = (self.stats['total_inference_time'] / 
                                    self.stats['total_inferences']) * 1000
                total_fps = self.stats['total_frames'] / self.stats['total_inference_time']
                
                print(f"üìä Ï≤òÎ¶¨ ÌÜµÍ≥Ñ:")
                print(f"   - Ï¥ù ÌîÑÎ†àÏûÑ: {self.stats['total_frames']}")
                print(f"   - Ï¥ù Ï∂îÎ°†: {self.stats['total_inferences']}")
                print(f"   - ÌèâÍ∑† Ï∂îÎ°† ÏãúÍ∞Ñ: {avg_inference_time:.1f}ms")
                print(f"   - Ï¥ù FPS: {total_fps:.1f}")
                print(f"   - ÌîÑÎ†àÏûÑ/Ï∂îÎ°†: {self.stats['total_frames'] / self.stats['total_inferences']:.1f}")


# ÏÇ¨Ïö© ÏòàÏãú
if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv('/home/hiperwall/Ai_modules/Ai/env/aws.env')
    
    detector = OptimizedSingleDetector(
        app_batch_size=4,       # Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î†àÎ≤® Î∞∞Ïπò ÌÅ¨Í∏∞
        max_wait_time=0.05,     # 50ms ÏµúÎåÄ ÎåÄÍ∏∞
        conf_threshold=0.3,
        iou_threshold=0.45
    )
    
    detector.run()