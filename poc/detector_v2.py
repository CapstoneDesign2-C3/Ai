import numpy as np
import cv2
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import time
import json
import threading
import queue
from collections import deque
from pathlib import Path

from kafka_util import consumers, producers
import os

class OptimizedSingleDetector: 
    def __init__(self, class_names_path=None, conf_threshold=0.25, iou_threshold=0.45,
                 app_batch_size=None, max_wait_time=0.05):
        """
        Args:
            app_batch_size: ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë°°ì¹˜ í¬ê¸° (Noneì´ë©´ ì—”ì§„ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©)
            max_wait_time: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        """
        # Kafka ì„¤ì •
        self.frame_consumer = consumers.FrameConsumer()
        self.result_producer = producers.DetectedResultProducer()
        
        # ëª¨ë¸ ì„¤ì •
        self.engine_path = os.getenv('ENGINE_PATH')
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.max_wait_time = max_wait_time
        
        # í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ
        self.class_names = self._load_class_names(class_names_path)
        self.colors = np.random.uniform(0, 255, size=(len(self.class_names), 3))
        
        # TensorRT ì—”ì§„ ë¡œë“œ
        self.logger = trt.Logger(trt.Logger.WARNING)
        self.engine = self._load_engine()
        self.context = self.engine.create_execution_context()
        
        # ì—”ì§„ì˜ ì‹¤ì œ ë°°ì¹˜ í¬ê¸° í™•ì¸
        self.engine_batch_size, self.input_shape = self._get_engine_info()
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°ì¹˜ í¬ê¸° ê²°ì •
        if app_batch_size is None:
            self.app_batch_size = self.engine_batch_size
        else:
            self.app_batch_size = min(app_batch_size, self.engine_batch_size)
        
        # ë²„í¼ í• ë‹¹
        self._setup_buffers()
        
        # í”„ë ˆì„ í
        self.frame_queue = queue.Queue(maxsize=self.app_batch_size * 4)
        self.processing_thread = None
        self.stop_event = threading.Event()
        
        # í†µê³„
        self.stats = {
            'total_frames': 0,
            'total_inferences': 0,
            'total_inference_time': 0,
            'lock': threading.Lock()
        }
        
        print(f"âœ… ìµœì í™”ëœ Detector ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ì—”ì§„ ë°°ì¹˜ í¬ê¸°: {self.engine_batch_size}")
        print(f"   - ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°ì¹˜ í¬ê¸°: {self.app_batch_size}")
        print(f"   - ì…ë ¥ í˜•íƒœ: {self.input_shape}")
        print(f"   - ìµœëŒ€ ëŒ€ê¸° ì‹œê°„: {max_wait_time*1000:.1f}ms")
    
    def _load_class_names(self, class_names_path):
        """í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ"""
        if class_names_path and Path(class_names_path).exists():
            try:
                with open(class_names_path, 'r', encoding='utf-8') as f:
                    if class_names_path.endswith('.json'):
                        data = json.load(f)
                        return data.get('names', list(data.values()))
                    else:
                        return [line.strip() for line in f.readlines() if line.strip()]
            except Exception as e:
                print(f"âš ï¸  í´ë˜ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
            'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
            'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
    
    def _load_engine(self):
        """TensorRT ì—”ì§„ ë¡œë“œ"""
        try:
            with open(self.engine_path, 'rb') as f, trt.Runtime(self.logger) as runtime:
                engine = runtime.deserialize_cuda_engine(f.read())
            print(f"âœ… TensorRT ì—”ì§„ ë¡œë“œ ì™„ë£Œ: {self.engine_path}")
            return engine
        except Exception as e:
            print(f"âŒ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_engine_info(self):
        """ì—”ì§„ì˜ ì‹¤ì œ ë°°ì¹˜ í¬ê¸°ì™€ ì…ë ¥ í˜•íƒœ í™•ì¸"""
        if hasattr(self.engine, 'num_io_tensors'):
            # TensorRT 8.5+ API
            for i in range(self.engine.num_io_tensors):
                tensor_name = self.engine.get_tensor_name(i)
                if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                    shape = self.context.get_tensor_shape(tensor_name)
                    batch_size = shape[0] if shape[0] > 0 else 1  # -1ì´ë©´ ë™ì , ì–‘ìˆ˜ë©´ ê³ ì •
                    return batch_size, shape
        else:
            # TensorRT 7.x/8.x API
            for binding in self.engine:
                if self.engine.binding_is_input(binding):
                    shape = self.context.get_binding_shape(binding)
                    batch_size = shape[0] if shape[0] > 0 else 1
                    return batch_size, shape
        
        return 1, None  # ê¸°ë³¸ê°’
    
    def _setup_buffers(self):
        """GPU ë²„í¼ ì„¤ì •"""
        self.inputs = []
        self.outputs = []
        self.bindings = []
        self.stream = cuda.Stream()
        
        if hasattr(self.engine, 'num_io_tensors'):
            for i in range(self.engine.num_io_tensors):
                tensor_name = self.engine.get_tensor_name(i)
                dtype = trt.nptype(self.engine.get_tensor_dtype(tensor_name))
                
                if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                    shape = self.input_shape
                    size = trt.volume(shape) if shape[0] > 0 else trt.volume(shape[1:]) * self.engine_batch_size
                    
                    host_mem = cuda.pagelocked_empty(size, dtype)
                    device_mem = cuda.mem_alloc(host_mem.nbytes)
                    self.bindings.append(int(device_mem))
                    self.inputs.append({'host': host_mem, 'device': device_mem, 
                                      'shape': shape, 'name': tensor_name})
                    self.input_name = tensor_name
                else:
                    shape = self.context.get_tensor_shape(tensor_name)
                    # ì¶œë ¥ í¬ê¸° ê³„ì‚° (ë°°ì¹˜ í¬ê¸° ê³ ë ¤)
                    if shape[0] <= 0:  # ë™ì  ë°°ì¹˜
                        actual_shape = (self.engine_batch_size,) + shape[1:]
                        size = trt.volume(actual_shape)
                    else:
                        size = trt.volume(shape)
                        actual_shape = shape
                    
                    host_mem = cuda.pagelocked_empty(size, dtype)
                    device_mem = cuda.mem_alloc(host_mem.nbytes)
                    self.bindings.append(int(device_mem))
                    self.outputs.append({'host': host_mem, 'device': device_mem, 
                                       'shape': actual_shape, 'name': tensor_name})
                    self.output_name = tensor_name
        
        print(f"ğŸ”§ ë²„í¼ ì„¤ì • ì™„ë£Œ:")
        print(f"   - ì…ë ¥ ë²„í¼ í¬ê¸°: {self.inputs[0]['host'].nbytes / 1024 / 1024:.1f} MB")
        print(f"   - ì¶œë ¥ ë²„í¼ í¬ê¸°: {self.outputs[0]['host'].nbytes / 1024 / 1024:.1f} MB")
    
    def preprocess_images(self, images):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë°°ì¹˜ ë˜ëŠ” ë‹¨ì¼)"""
        if self.engine_batch_size == 1:
            # ì—”ì§„ì´ ë‹¨ì¼ ë°°ì¹˜ë§Œ ì§€ì›í•˜ëŠ” ê²½ìš°
            return self._preprocess_single_batch(images)
        else:
            # ì—”ì§„ì´ ì§„ì§œ ë°°ì¹˜ë¥¼ ì§€ì›í•˜ëŠ” ê²½ìš°
            return self._preprocess_true_batch(images)
    
    def _preprocess_single_batch(self, images):
        """ë‹¨ì¼ ì´ë¯¸ì§€ì”© ì „ì²˜ë¦¬ (ì—”ì§„ ë°°ì¹˜ í¬ê¸° = 1)"""
        preprocessed = []
        metadata = []
        
        _, input_h, input_w = self.input_shape[1], self.input_shape[2], self.input_shape[3]
        
        for image in images:
            img_h, img_w = image.shape[:2]
            scale = min(input_w / img_w, input_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            padded = np.full((input_h, input_w, 3), 114, dtype=np.uint8)
            pad_x = (input_w - new_w) // 2
            pad_y = (input_h - new_h) // 2
            padded[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized
            
            tensor = padded.astype(np.float32) / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))
            tensor = np.expand_dims(tensor, axis=0)  # [1, 3, H, W]
            
            preprocessed.append(tensor)
            metadata.append({'scale': scale, 'pad_x': pad_x, 'pad_y': pad_y})
        
        return preprocessed, metadata
    
    def _preprocess_true_batch(self, images):
        """ì§„ì§œ ë°°ì¹˜ ì „ì²˜ë¦¬ (ì—”ì§„ì´ ë°°ì¹˜ ì§€ì›)"""
        batch_tensors = []
        metadata = []
        
        _, input_h, input_w = self.input_shape[1], self.input_shape[2], self.input_shape[3]
        
        for image in images:
            img_h, img_w = image.shape[:2]
            scale = min(input_w / img_w, input_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            padded = np.full((input_h, input_w, 3), 114, dtype=np.uint8)
            pad_x = (input_w - new_w) // 2
            pad_y = (input_h - new_h) // 2
            padded[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized
            
            tensor = padded.astype(np.float32) / 255.0
            tensor = np.transpose(tensor, (2, 0, 1))
            
            batch_tensors.append(tensor)
            metadata.append({'scale': scale, 'pad_x': pad_x, 'pad_y': pad_y})
        
        # ì§„ì§œ ë°°ì¹˜ë¡œ ê²°í•©
        batch_tensor = np.stack(batch_tensors, axis=0)  # [N, 3, H, W]
        
        # ì—”ì§„ ë°°ì¹˜ í¬ê¸°ì— ë§ì¶° íŒ¨ë”©
        if len(batch_tensors) < self.engine_batch_size:
            padding_count = self.engine_batch_size - len(batch_tensors)
            padding = np.zeros((padding_count,) + batch_tensor.shape[1:], dtype=np.float32)
            batch_tensor = np.concatenate([batch_tensor, padding], axis=0)
        
        return batch_tensor, metadata
    
    def postprocess_results(self, outputs, metadata_list, actual_batch_size):
        """í›„ì²˜ë¦¬ ê²°ê³¼"""
        results = []
        
        if self.engine_batch_size == 1:
            # ë‹¨ì¼ ì¶”ë¡  ê²°ê³¼ë“¤
            for i, (output, metadata) in enumerate(zip(outputs, metadata_list)):
                boxes, scores, class_ids = self._postprocess_single(output, metadata)
                results.append((boxes, scores, class_ids))
        else:
            # ì§„ì§œ ë°°ì¹˜ ê²°ê³¼
            batch_output = outputs[0]  # [batch_size, ...]
            for i in range(actual_batch_size):
                single_output = batch_output[i]  # ië²ˆì§¸ ì´ë¯¸ì§€ ê²°ê³¼
                metadata = metadata_list[i]
                boxes, scores, class_ids = self._postprocess_single(single_output, metadata)
                results.append((boxes, scores, class_ids))
        
        return results
    
    def _postprocess_single(self, output, metadata):
        """ë‹¨ì¼ ì´ë¯¸ì§€ í›„ì²˜ë¦¬"""
        if len(output.shape) == 3:
            output = output[0]
        if len(output.shape) == 2 and output.shape[0] < output.shape[1]:
            output = output.T
        
        x_centers = output[:, 0]
        y_centers = output[:, 1]
        widths = output[:, 2]
        heights = output[:, 3]
        class_confs = output[:, 4:]
        
        max_confs = np.max(class_confs, axis=1)
        class_ids = np.argmax(class_confs, axis=1)
        
        valid_mask = max_confs > self.conf_threshold
        if not np.any(valid_mask):
            return np.array([]), np.array([]), np.array([])
        
        # ì¢Œí‘œ ë³€í™˜
        scale = metadata['scale']
        pad_x = metadata['pad_x']
        pad_y = metadata['pad_y']
        
        x_centers = (x_centers[valid_mask] - pad_x) / scale
        y_centers = (y_centers[valid_mask] - pad_y) / scale
        widths = widths[valid_mask] / scale
        heights = heights[valid_mask] / scale
        max_confs = max_confs[valid_mask]
        class_ids = class_ids[valid_mask]
        
        x1s = x_centers - widths / 2
        y1s = y_centers - heights / 2
        boxes = np.column_stack([x1s, y1s, widths, heights])
        
        # NMS
        if len(boxes) > 0:
            indices = cv2.dnn.NMSBoxes(boxes.tolist(), max_confs.tolist(),
                                      self.conf_threshold, self.iou_threshold)
            if len(indices) > 0:
                if isinstance(indices, tuple):
                    indices = indices[0] if len(indices) > 0 else []
                if len(indices) > 0:
                    indices = indices.flatten() if hasattr(indices, 'flatten') else indices
                    return boxes[indices], max_confs[indices], class_ids[indices]
        
        return np.array([]), np.array([]), np.array([])
    
    def infer_batch(self, images, camera_ids):
        """ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰"""
        if not images:
            return []
        
        actual_batch_size = len(images)
        start_time = time.time()
        
        # ì „ì²˜ë¦¬
        preprocessed, metadata = self.preprocess_images(images)
        
        if self.engine_batch_size == 1:
            # ì—”ì§„ì´ ë‹¨ì¼ ë°°ì¹˜ë§Œ ì§€ì› - ìˆœì°¨ ì‹¤í–‰
            all_outputs = []
            for tensor in preprocessed:
                np.copyto(self.inputs[0]['host'], tensor.ravel())
                cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
                
                # ë™ì  í˜•íƒœ ì„¤ì • (í•„ìš”ì‹œ)
                if hasattr(self.context, 'set_tensor_shape'):
                    self.context.set_tensor_shape(self.input_name, tensor.shape)
                
                # ì¶”ë¡  ì‹¤í–‰
                if hasattr(self.context, 'execute_async_v3'):
                    self.context.set_tensor_address(self.input_name, self.inputs[0]['device'])
                    self.context.set_tensor_address(self.output_name, self.outputs[0]['device'])
                    self.context.execute_async_v3(stream_handle=self.stream.handle)
                else:
                    self.context.execute_v2(bindings=self.bindings)
                
                # ê²°ê³¼ ë³µì‚¬
                cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
                self.stream.synchronize()
                
                # ì¶œë ¥ ì €ì¥
                output_data = self.outputs[0]['host'].reshape(self.outputs[0]['shape'])
                all_outputs.append(output_data)
        else:
            # ì—”ì§„ì´ ì§„ì§œ ë°°ì¹˜ ì§€ì› - í•œë²ˆì— ì‹¤í–‰
            batch_tensor = preprocessed
            np.copyto(self.inputs[0]['host'], batch_tensor.ravel())
            cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
            
            # ë™ì  í˜•íƒœ ì„¤ì •
            if hasattr(self.context, 'set_tensor_shape'):
                self.context.set_tensor_shape(self.input_name, batch_tensor.shape)
            
            # ì¶”ë¡  ì‹¤í–‰
            if hasattr(self.context, 'execute_async_v3'):
                self.context.set_tensor_address(self.input_name, self.inputs[0]['device'])
                self.context.set_tensor_address(self.output_name, self.outputs[0]['device'])
                self.context.execute_async_v3(stream_handle=self.stream.handle)
            else:
                self.context.execute_v2(bindings=self.bindings)
            
            # ê²°ê³¼ ë³µì‚¬
            cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
            self.stream.synchronize()
            
            all_outputs = [self.outputs[0]['host'].reshape(self.outputs[0]['shape'])]
        
        inference_time = time.time() - start_time
        
        # í›„ì²˜ë¦¬
        results = self.postprocess_results(all_outputs, metadata, actual_batch_size)
        
        # Kafka ê²°ê³¼ ì „ì†¡
        for i, (camera_id, (boxes, scores, class_ids)) in enumerate(zip(camera_ids, results)):
            detections = []
            for box, score, class_id in zip(boxes, scores, class_ids):
                x1, y1, w, h = box.astype(int)
                detections.append({
                    'bbox': [float(x1), float(y1), float(w), float(h)],
                    'confidence': float(score),
                    'class': int(class_id),
                    'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                })
            
            payload = {
                'camera_id': camera_id,
                'timestamp': time.time(),
                'detections': detections,
                'inference_time_ms': inference_time * 1000,
                'batch_size': actual_batch_size,
                'engine_batch_size': self.engine_batch_size
            }
            
            payload_bytes = json.dumps(payload).encode('utf-8')
            self.result_producer.send_message(
                key=camera_id.encode('utf-8'),
                value=payload_bytes
            )
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        with self.stats['lock']:
            self.stats['total_frames'] += actual_batch_size
            self.stats['total_inferences'] += 1
            self.stats['total_inference_time'] += inference_time
        
        return results
    
    def batch_processor(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ì›Œì»¤"""
        batch_buffer = []
        last_process_time = time.time()
        
        while not self.stop_event.is_set():
            try:
                timeout = max(0.001, self.max_wait_time - (time.time() - last_process_time))
                
                try:
                    item = self.frame_queue.get(timeout=timeout)
                    if item is None:
                        break
                    batch_buffer.append(item)
                except queue.Empty:
                    pass
                
                # ì²˜ë¦¬ ì¡°ê±´
                should_process = (
                    len(batch_buffer) >= self.app_batch_size or
                    (len(batch_buffer) > 0 and 
                     time.time() - last_process_time >= self.max_wait_time)
                )
                
                if should_process and batch_buffer:
                    camera_ids, images = zip(*batch_buffer)
                    self.infer_batch(list(images), list(camera_ids))
                    self.result_producer.flush()
                    
                    batch_buffer.clear()
                    last_process_time = time.time()
                    
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                batch_buffer.clear()
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print(f"ğŸš€ ìµœì í™”ëœ ê²€ì¶œ ì‹œì‘")
        
        self.processing_thread = threading.Thread(target=self.batch_processor)
        self.processing_thread.start()
        
        try:
            for msg in self.frame_consumer.consumer:
                if self.stop_event.is_set():
                    break
                
                camera_id = msg.key.decode('utf-8')
                frame_bytes = msg.value
                
                try:
                    arr = np.frombuffer(frame_bytes, dtype=np.uint8)
                    frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)
                    if frame is None:
                        continue
                    
                    if not self.frame_queue.full():
                        self.frame_queue.put((camera_id, frame), block=False)
                    else:
                        print(f"âš ï¸ í í¬í™” - {camera_id} í”„ë ˆì„ ë“œë¡­")
                        
                except Exception as e:
                    print(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜ {camera_id}: {e}")
                
                if self.stats['total_frames'] % 50 == 0:
                    self.print_stats()
                    
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì¢…ë£Œ")
        finally:
            self.stop_event.set()
            self.frame_queue.put(None)
            if self.processing_thread:
                self.processing_thread.join()
            self.result_producer.producer.flush()
            self.print_stats()
    
    def print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        with self.stats['lock']:
            if self.stats['total_inferences'] > 0:
                avg_inference_time = (self.stats['total_inference_time'] / 
                                    self.stats['total_inferences']) * 1000
                total_fps = self.stats['total_frames'] / self.stats['total_inference_time']
                
                print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
                print(f"   - ì´ í”„ë ˆì„: {self.stats['total_frames']}")
                print(f"   - ì´ ì¶”ë¡ : {self.stats['total_inferences']}")
                print(f"   - í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference_time:.1f}ms")
                print(f"   - ì´ FPS: {total_fps:.1f}")
                print(f"   - í”„ë ˆì„/ì¶”ë¡ : {self.stats['total_frames'] / self.stats['total_inferences']:.1f}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv('/home/hiperwall/Ai_modules/Ai/env/aws.env')
    
    detector = OptimizedSingleDetector(
        app_batch_size=4,       # ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë°°ì¹˜ í¬ê¸°
        max_wait_time=0.05,     # 50ms ìµœëŒ€ ëŒ€ê¸°
        conf_threshold=0.3,
        iou_threshold=0.45
    )
    
    detector.run()