#!/usr/bin/env python3
"""
DetectorAndTrackerì™€ Kafka ì™„ì „ ì—°ë™ ì˜ˆì‹œ

ì´ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤:
1. ì¹´ë©”ë¼ í”„ë ˆì„ ìˆ˜ì‹  (FrameConsumer)
2. YOLOv11 + DeepSort ì²˜ë¦¬ (DetectorAndTracker)
3. ê²€ì¶œ/ì¶”ì  ê²°ê³¼ Kafka ì „ì†¡ (Producer)
4. ê²°ê³¼ ìˆ˜ì‹  ë° ì²˜ë¦¬ (Consumer)
"""

import cv2
import numpy as np
import time
import threading
import json
from typing import Dict, Optional, Any
import logging
import signal
import sys
from pathlib import Path

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from tracking_module.new_dt import DetectorAndTracker
from kafka_util.improved_kafka_consumers import ConsumerManager, FrameConsumer
from kafka_util.improved_kafka_producers import dcreate_frame_producer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class VideoStreamProcessor:
    """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° Kafka ì—°ë™ í´ë˜ìŠ¤"""
    
    def __init__(self, camera_id: str, engine_path: str, 
                 video_source: Any = 0,  # ì›¹ìº (0) ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
                 enable_display: bool = True,
                 send_frames_to_kafka: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            camera_id: ì¹´ë©”ë¼ ID
            engine_path: TensorRT ì—”ì§„ íŒŒì¼ ê²½ë¡œ
            video_source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (ì›¹ìº  ë²ˆí˜¸ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ)
            enable_display: í™”ë©´ ì¶œë ¥ ì—¬ë¶€
            send_frames_to_kafka: í”„ë ˆì„ Kafka ì „ì†¡ ì—¬ë¶€
        """
        self.camera_id = camera_id
        self.video_source = video_source
        self.enable_display = enable_display
        self.send_frames_to_kafka = send_frames_to_kafka
        
        # ë¹„ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™”
        self.cap = cv2.VideoCapture(video_source)
        if not self.cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_source}")
        
        # DetectorAndTracker ì´ˆê¸°í™”
        self.detector = DetectorAndTracker(
            camera_id=camera_id,
            engine_path=engine_path,
            conf_threshold=0.25,
            iou_threshold=0.45,
            enable_kafka=True,
            enable_tracking=True,
            send_detection_results=True,
            send_tracking_results=True
        )
        
        # Kafka Producer (í”„ë ˆì„ ì „ì†¡ìš©)
        self.frame_producer = None
        if send_frames_to_kafka:
            try:
                self.frame_producer = create_frame_producer(camera_id)
                logger.info("âœ… FrameProducer ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ FrameProducer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.send_frames_to_kafka = False
        
        # í†µê³„ ë³€ìˆ˜
        self.stats = {
            'total_frames': 0,
            'processed_frames': 0,
            'detection_count': 0,
            'tracking_count': 0,
            'avg_fps': 0.0,
            'avg_inference_time': 0.0
        }
        
        self._running = False
        self._start_time = time.time()
        
        logger.info(f"âœ… VideoStreamProcessor ì´ˆê¸°í™” ì™„ë£Œ - Camera: {camera_id}")
    
    def start_processing(self):
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘"""
        if self._running:
            logger.warning("ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.")
            return
        
        self._running = True
        self._start_time = time.time()
        
        logger.info("ğŸš€ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘")
        
        try:
            while self._running:
                ret, frame = self.cap.read()
                
                if not ret:
                    logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                self.stats['total_frames'] += 1
                
                # í”„ë ˆì„ ì²˜ë¦¬
                self._process_frame(frame)
                
                # FPS ê³„ì‚°
                elapsed_time = time.time() - self._start_time
                if elapsed_time > 0:
                    self.stats['avg_fps'] = self.stats['processed_frames'] / elapsed_time
                
                # ESC í‚¤ë¡œ ì¢…ë£Œ (display ëª¨ë“œì¼ ë•Œ)
                if self.enable_display:
                    key = cv2.waitKey(1) & 0xFF
                    if key == 27:  # ESC
                        break
                
        except Exception as e:
            logger.error(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            self.stop_processing()
    
    def _process_frame(self, frame: np.ndarray):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        try:
            frame_start_time = time.time()
            
            # 1. DetectorAndTrackerë¡œ ì¶”ë¡  ë° ì¶”ì 
            tracks, timing_info = self.detector.detect_and_track(frame, debug=False)
            
            # 2. í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['processed_frames'] += 1
            if timing_info.get('total', 0) > 0:
                # ì´ë™ í‰ê· ìœ¼ë¡œ ì¶”ë¡  ì‹œê°„ ê³„ì‚°
                current_avg = self.stats['avg_inference_time']
                new_time = timing_info['total']
                alpha = 0.1  # ì´ë™ í‰ê·  ê³„ìˆ˜
                self.stats['avg_inference_time'] = current_avg * (1 - alpha) + new_time * alpha
            
            # 3. í”„ë ˆì„ì— ê²°ê³¼ ê·¸ë¦¬ê¸° (displayìš©)
            if self.enable_display or self.send_frames_to_kafka:
                # ê²€ì¶œ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ê·¸ë¦¬ê¸°
                if hasattr(self.detector, '_last_boxes'):  # ë§ˆì§€ë§‰ ê²€ì¶œ ê²°ê³¼ ì‚¬ìš©
                    display_frame = self.detector.draw_detections(
                        frame, 
                        self.detector._last_boxes,
                        self.detector._last_scores, 
                        self.detector._last_class_ids
                    )
                else:
                    display_frame = frame.copy()
                
                # ì¶”ì  ì •ë³´ ê·¸ë¦¬ê¸°
                self._draw_tracking_info(display_frame, tracks, timing_info)
                
                # í™”ë©´ ì¶œë ¥
                if self.enable_display:
                    cv2.imshow(f'Detection & Tracking - {self.camera_id}', display_frame)
                
                # Kafkaë¡œ ê²°ê³¼ í”„ë ˆì„ ì „ì†¡
                if self.send_frames_to_kafka and self.frame_producer:
                    try:
                        result = self.frame_producer.send_message(display_frame, quality=80)
                        if result.get('status_code') != 200:
                            logger.warning(f"í”„ë ˆì„ ì „ì†¡ ì‹¤íŒ¨: {result.get('error')}")
                    except Exception as e:
                        logger.error(f"í”„ë ˆì„ Kafka ì „ì†¡ ì˜¤ë¥˜: {e}")
            
            # 4. í†µê³„ ì—…ë°ì´íŠ¸
            if len(tracks) > 0:
                self.stats['tracking_count'] += len([t for t in tracks if t.is_confirmed()])
            
            frame_process_time = (time.time() - frame_start_time) * 1000
            
            # ì£¼ê¸°ì ìœ¼ë¡œ í†µê³„ ì¶œë ¥ (100í”„ë ˆì„ë§ˆë‹¤)
            if self.stats['processed_frames'] % 100 == 0:
                self._log_statistics()
                
        except Exception as e:
            logger.error(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    def _draw_tracking_info(self, frame: np.ndarray, tracks: list, timing_info: Dict):
        """ì¶”ì  ì •ë³´ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        try:
            # ìƒë‹¨ì— ì •ë³´ í‘œì‹œ
            info_y = 30
            cv2.putText(frame, f"Camera: {self.camera_id}", (10, info_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            info_y += 25
            cv2.putText(frame, f"FPS: {self.stats['avg_fps']:.1f}", (10, info_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            info_y += 25
            cv2.putText(frame, f"Inference: {timing_info.get('total', 0):.1f}ms", (10, info_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            info_y += 25
            active_tracks = len([t for t in tracks if t.is_confirmed()])
            cv2.putText(frame, f"Active Tracks: {active_tracks}", (10, info_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ê° íŠ¸ë™ì˜ ID í‘œì‹œ
            for track in tracks:
                if not track.is_confirmed():
                    continue
                
                # íŠ¸ë™ ë°”ìš´ë”© ë°•ìŠ¤
                l, t, r, b = track.to_ltrb()
                
                # íŠ¸ë™ ID í‘œì‹œ
                cv2.rectangle(frame, (l, t), (r, b), (0, 255, 255), 2)
                cv2.putText(frame, f"ID: {track.track_id}", (l, t-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                
        except Exception as e:
            logger.error(f"âŒ ì¶”ì  ì •ë³´ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    def _log_statistics(self):
        """í†µê³„ ì •ë³´ ë¡œê¹…"""
        detector_stats = self.detector.get_statistics()
        
        logger.info("ğŸ“Š ì²˜ë¦¬ í†µê³„:")
        logger.info(f"   ì´ í”„ë ˆì„: {self.stats['total_frames']}")
        logger.info(f"   ì²˜ë¦¬ í”„ë ˆì„: {self.stats['processed_frames']}")
        logger.info(f"   í‰ê·  FPS: {self.stats['avg_fps']:.2f}")
        logger.info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {self.stats['avg_inference_time']:.2f}ms")
        logger.info(f"   í™œì„± ì¶”ì : {detector_stats['active_tracks']}")
    
    def stop_processing(self):
        """ì²˜ë¦¬ ì¤‘ë‹¨"""
        if not self._running:
            return
        
        self._running = False
        
        try:
            # ìì› ì •ë¦¬
            if self.cap:
                self.cap.release()
            
            if self.enable_display:
                cv2.destroyAllWindows()
            
            if self.frame_producer:
                self.frame_producer.close()
            
            if self.detector:
                self.detector.cleanup()
            
            # ìµœì¢… í†µê³„ ì¶œë ¥
            self._log_statistics()
            
            logger.info("âœ… VideoStreamProcessor ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """ì „ì²´ í†µê³„ ì •ë³´ ë°˜í™˜"""
        detector_stats = self.detector.get_statistics() if self.detector else {}
        
        return {
            "camera_id": self.camera_id,
            "video_stats": self.stats,
            "detector_stats": detector_stats,
            "running": self._running
        }


class KafkaResultMonitor:
    """Kafka ê²°ê³¼ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.consumer_manager = ConsumerManager()
        self.detection_count = 0
        self.tracking_count = 0
        
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        logger.info("ğŸ” Kafka ê²°ê³¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        # ê²€ì¶œ ê²°ê³¼ ëª¨ë‹ˆí„°ë§
        self.consumer_manager.add_detection_consumer(
            "monitor_detection",
            self._handle_detection_result,
            group_id="monitor_detection_group"
        )
        
        # ì¶”ì  ê²°ê³¼ ëª¨ë‹ˆí„°ë§
        self.consumer_manager.add_tracking_consumer(
            "monitor_tracking",
            self._handle_tracking_result,
            group_id="monitor_tracking_group"
        )
    
    def _handle_detection_result(self, camera_id: str, detection_data: Dict):
        """ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬"""
        self.detection_count += 1
        detections = detection_data.get('detections', [])
        
        if self.detection_count % 50 == 0:  # 50ê°œë§ˆë‹¤ ë¡œê·¸
            logger.info(f"ğŸ“Š ê²€ì¶œ ê²°ê³¼ - Camera: {camera_id}, "
                       f"ê°ì²´ ìˆ˜: {len(detections)}, "
                       f"ì´ ê²€ì¶œ ë©”ì‹œì§€: {self.detection_count}")
    
    def _handle_tracking_result(self, camera_id: str, tracking_data: Dict, 
                               crop_image: Optional[np.ndarray]):
        """ì¶”ì  ê²°ê³¼ ì²˜ë¦¬"""
        self.tracking_count += 1
        track_id = tracking_data.get('track_id')
        class_name = tracking_data.get('class_name', 'unknown')
        
        if self.tracking_count % 10 == 0:  # 10ê°œë§ˆë‹¤ ë¡œê·¸
            logger.info(f"ğŸ¯ ì¶”ì  ê²°ê³¼ - Camera: {camera_id}, "
                       f"Track ID: {track_id}, "
                       f"í´ë˜ìŠ¤: {class_name}, "
                       f"ì´ ì¶”ì  ë©”ì‹œì§€: {self.tracking_count}")
            
            if crop_image is not None:
                logger.info(f"   í¬ë¡­ ì´ë¯¸ì§€ í¬ê¸°: {crop_image.shape}")
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨"""
        self.consumer_manager.close_all()
        logger.info("ğŸ›‘ Kafka ê²°ê³¼ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨")
    
    def get_statistics(self) -> Dict[str, Any]:
        """ëª¨ë‹ˆí„°ë§ í†µê³„"""
        return {
            "detection_messages": self.detection_count,
            "tracking_messages": self.tracking_count,
            "consumer_stats": self.consumer_manager.get_statistics()
        }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    CAMERA_ID = "camera_001"
    ENGINE_PATH = "yolo_engine/yolo11m_fp16.engine"  # ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”
    VIDEO_SOURCE = "./sample.mp4"# ì›¹ìº  ì‚¬ìš©, íŒŒì¼ì˜ ê²½ìš° ê²½ë¡œ ì…ë ¥ 
    
    # ì—”ì§„ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(ENGINE_PATH).exists():
        logger.error(f"âŒ TensorRT ì—”ì§„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ENGINE_PATH}")
        logger.info("ğŸ’¡ ENGINE_PATHë¥¼ ì‹¤ì œ ì—”ì§„ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        return
    
    processor = None
    monitor = None
    
    def signal_handler(sig, frame):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
        logger.info("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
        if processor:
            processor.stop_processing()
        if monitor:
            monitor.stop_monitoring()
        sys.exit(0)
    
    # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # Kafka ê²°ê³¼ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì„ íƒì‚¬í•­)
        monitor = KafkaResultMonitor()
        monitor.start_monitoring()
        
        # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘
        processor = VideoStreamProcessor(
            camera_id=CAMERA_ID,
            engine_path=ENGINE_PATH,
            video_source=VIDEO_SOURCE,
            enable_display=True,
            send_frames_to_kafka=True
        )
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í†µê³„ ì¶œë ¥
        def print_stats():
            while True:
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤
                if processor:
                    stats = processor.get_statistics()
                    logger.info("ğŸ“Š ì „ì²´ í†µê³„:")
                    logger.info(f"   ë¹„ë””ì˜¤: {json.dumps(stats['video_stats'], indent=2)}")
                
                if monitor:
                    monitor_stats = monitor.get_statistics()
                    logger.info(f"   ëª¨ë‹ˆí„°ë§: {json.dumps(monitor_stats, indent=2)}")
        
        stats_thread = threading.Thread(target=print_stats, daemon=True)
        stats_thread.start()
        
        # ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
        processor.start_processing()
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        logger.info("ğŸ”š í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        if processor:
            processor.stop_processing()
        if monitor:
            monitor.stop_monitoring()


if __name__ == "__main__":
    main()