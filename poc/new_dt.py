import numpy as np
import cv2
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import time
import json
import os
import io
import base64
from pathlib import Path
from typing import List, Tuple, Dict, Optional
from PIL import Image

from dotenv import load_dotenv
from deep_sort_realtime.deepsort_tracker import DeepSort

# ìˆ˜ì •ëœ import - ê°œì„ ëœ producers ì‚¬ìš©
from kafka_util.improved_kafka_producers import (
    create_detected_result_producer,
    create_track_result_producer
)

class DetectorAndTracker:
    """
    YOLOv11 TensorRT ê¸°ë°˜ ê°ì²´ ê²€ì¶œ ë° DeepSort ì¶”ì  í´ë˜ìŠ¤
    Kafkaì™€ ì™„ì „ ì—°ë™ ê°€ëŠ¥
    """
    
    # ìƒìˆ˜ ì •ì˜
    DEFAULT_PADDING_COLOR = 114
    NORMALIZATION_FACTOR = 255.0
    DEFAULT_FONT = cv2.FONT_HERSHEY_SIMPLEX
    DEFAULT_FONT_SCALE = 0.7
    DEFAULT_THICKNESS = 2
    
    # COCO í´ë˜ìŠ¤ ì´ë¦„ë“¤
    COCO_CLASSES = [
        'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
        'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
        'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
        'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
        'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
        'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
        'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
        'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
        'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
        'toothbrush'
    ]

    def __init__(self, 
                 camera_id: str,
                 engine_path: Optional[str] = None,
                 class_names_path: Optional[str] = None, 
                 conf_threshold: float = 0.25, 
                 iou_threshold: float = 0.45,
                 enable_kafka: bool = True,
                 enable_tracking: bool = True,
                 send_detection_results: bool = True,
                 send_tracking_results: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            camera_id: ì¹´ë©”ë¼ ID (Kafka ë©”ì‹œì§€ í‚¤ë¡œ ì‚¬ìš©)
            engine_path: TensorRT ì—”ì§„ íŒŒì¼ ê²½ë¡œ
            class_names_path: í´ë˜ìŠ¤ ì´ë¦„ íŒŒì¼ ê²½ë¡œ
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: IoU ì„ê³„ê°’
            enable_kafka: Kafka ì‚¬ìš© ì—¬ë¶€
            enable_tracking: ê°ì²´ ì¶”ì  ì‚¬ìš© ì—¬ë¶€
            send_detection_results: ê²€ì¶œ ê²°ê³¼ Kafka ì „ì†¡ ì—¬ë¶€
            send_tracking_results: ì¶”ì  ê²°ê³¼ Kafka ì „ì†¡ ì—¬ë¶€
        """
        # ê¸°ë³¸ ì„¤ì •
        self.camera_id = str(camera_id)
        self.engine_path = engine_path or os.getenv('ENGINE_PATH')
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.enable_kafka = enable_kafka
        self.enable_tracking = enable_tracking
        self.send_detection_results = send_detection_results
        self.send_tracking_results = send_tracking_results
        
        # ìœ íš¨ì„± ê²€ì‚¬
        self._validate_config()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_kafka()
        self._initialize_class_names(class_names_path)
        self._initialize_tensorrt()
        self._initialize_tracking()
        
        # ìƒíƒœ ë³€ìˆ˜
        self.local_id_set = set()
        self.frame_count = 0
        
        # ë§ˆì§€ë§‰ ê²€ì¶œ ê²°ê³¼ ì €ì¥ (draw_detectionsìš©)
        self._last_boxes = np.array([])
        self._last_scores = np.array([])
        self._last_class_ids = np.array([])
        
        print(f"âœ… DetectorAndTracker ì´ˆê¸°í™” ì™„ë£Œ - Camera ID: {self.camera_id}")

    def _validate_config(self) -> None:
        """ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬"""
        if not self.camera_id:
            raise ValueError("camera_idëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
            
        if not self.engine_path or not Path(self.engine_path).exists():
            raise ValueError(f"TensorRT ì—”ì§„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.engine_path}")
        
        if not (0.0 <= self.conf_threshold <= 1.0):
            raise ValueError(f"conf_thresholdëŠ” 0.0-1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤: {self.conf_threshold}")
        
        if not (0.0 <= self.iou_threshold <= 1.0):
            raise ValueError(f"iou_thresholdëŠ” 0.0-1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤: {self.iou_threshold}")

    def _initialize_kafka(self) -> None:
        """Kafka ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.result_producer = None
        self.track_result_producer = None
        
        if self.enable_kafka:
            try:
                # ê²€ì¶œ ê²°ê³¼ Producer (camera_id ë¶ˆí•„ìš”)
                if self.send_detection_results:
                    self.result_producer = create_detected_result_producer()
                    print("âœ… DetectedResultProducer ì´ˆê¸°í™” ì™„ë£Œ")
                
                # ì¶”ì  ê²°ê³¼ Producer (camera_id í•„ìš”)
                if self.send_tracking_results and self.enable_tracking:
                    self.track_result_producer = create_track_result_producer(self.camera_id)
                    print("âœ… TrackResultProducer ì´ˆê¸°í™” ì™„ë£Œ")
                    
            except Exception as e:
                print(f"âš ï¸ Kafka ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.enable_kafka = False

    def _initialize_class_names(self, class_names_path: Optional[str]) -> None:
        """í´ë˜ìŠ¤ ì´ë¦„ ì´ˆê¸°í™”"""
        self.class_names = self._load_class_names(class_names_path)
        self.colors = np.random.uniform(0, 255, size=(len(self.class_names), 3))

    def _initialize_tensorrt(self) -> None:
        """TensorRT ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            self.logger = trt.Logger(trt.Logger.WARNING)
            self.engine = self._load_engine()
            self.context = self.engine.create_execution_context()
            self.inputs, self.outputs, self.bindings, self.stream = self._allocate_buffers()
            self._print_engine_info()
            
            # ğŸ”¥ ì‹¤í–‰ ë©”ì„œë“œ ìš°ì„ ìˆœìœ„ ì„¤ì • (ì•ˆì •ì„± ìš°ì„ )
            self.execution_method = self._determine_execution_method()
            
        except Exception as e:
            raise RuntimeError(f"TensorRT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _determine_execution_method(self) -> str:
        """ìµœì ì˜ ì‹¤í–‰ ë©”ì„œë“œ ê²°ì •"""
        methods = []
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ì„œë“œ í™•ì¸
        methods = []
        if hasattr(self.context, 'execute_async_v3'):
            methods.append("execute_async_v3")
        if hasattr(self.context, 'execute_async_v2'):
            methods.append("execute_async_v2")
        if hasattr(self.context, 'execute_async'):
            methods.append("execute_async")
        if hasattr(self.context, 'execute_v2'):
            methods.append("execute_v2")
        if hasattr(self.context, 'execute'):
            methods.append("execute")
        # execute_async_v3ëŠ” ë¬¸ì œê°€ ìˆìœ¼ë¯€ë¡œ ì œì™¸
        
        print(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ë©”ì„œë“œ: {', '.join(methods)}")
        
        # ì•ˆì •ì„± ìš°ì„  ìˆœì„œë¡œ ì„ íƒ
        if "execute_async_v3" in methods:
            print("   - ì„ íƒëœ ì‹¤í–‰ ë©”ì„œë“œ: execute_v3 (ë™ê¸°, ì•ˆì •)")
            return "execute_async_v3"
        elif "execute" in methods:
            print("   - ì„ íƒëœ ì‹¤í–‰ ë©”ì„œë“œ: execute (ë™ê¸°, ë ˆê±°ì‹œ)")
            return "execute"
        elif "execute_async_v2" in methods:
            print("   - ì„ íƒëœ ì‹¤í–‰ ë©”ì„œë“œ: execute_async_v2 (ë¹„ë™ê¸°)")
            return "execute_async_v2"
        elif "execute_async" in methods:
            print("   - ì„ íƒëœ ì‹¤í–‰ ë©”ì„œë“œ: execute_async (ë¹„ë™ê¸°, ë ˆê±°ì‹œ)")
            return "execute_async"
        else:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ TensorRT ì‹¤í–‰ ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    def _initialize_tracking(self) -> None:
        """ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if self.enable_tracking:
            try:
                self.tracker = DeepSort(max_age=5)
                print("âœ… ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.enable_tracking = False

    def _load_class_names(self, class_names_path: Optional[str]) -> List[str]:
        """í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ"""
        if class_names_path and Path(class_names_path).exists():
            try:
                with open(class_names_path, 'r', encoding='utf-8') as f:
                    if class_names_path.endswith('.json'):
                        data = json.load(f)
                        return data.get('names', list(data.values()))
                    else:
                        return [line.strip() for line in f.readlines() if line.strip()]
            except Exception as e:
                print(f"âš ï¸ í´ë˜ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print("ğŸ“‹ ê¸°ë³¸ COCO í´ë˜ìŠ¤ ì‚¬ìš©")
        return self.COCO_CLASSES.copy()

    def _load_engine(self) -> trt.ICudaEngine:
        """TensorRT ì—”ì§„ ë¡œë“œ"""
        try:
            with open(self.engine_path, 'rb') as f, trt.Runtime(self.logger) as runtime:
                engine = runtime.deserialize_cuda_engine(f.read())
            print(f"âœ… TensorRT ì—”ì§„ ë¡œë“œ ì™„ë£Œ: {self.engine_path}")
            return engine
        except Exception as e:
            raise RuntimeError(f"ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def detect_and_track(self, frame: np.ndarray, debug: bool = False) -> Tuple[List, Dict]:
        """
        ê°ì²´ ê²€ì¶œ ë° ì¶”ì  (Kafka ì—°ë™ í¬í•¨)
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
            debug: ë””ë²„ê·¸ ëª¨ë“œ
            
        Returns:
            tracks: ì¶”ì  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            timing_info: íƒ€ì´ë° ì •ë³´
        """
        self.frame_count += 1
        
        # 1. ì¶”ë¡  ì‹¤í–‰
        boxes, scores, class_ids, timing_info = self.infer(frame, debug)
        
        # ë§ˆì§€ë§‰ ê²€ì¶œ ê²°ê³¼ ì €ì¥ (draw_detectionsìš©)
        self._last_boxes = boxes
        self._last_scores = scores
        self._last_class_ids = class_ids
        
        # 2. ê²€ì¶œ ê²°ê³¼ Kafka ì „ì†¡
        if self.enable_kafka and self.send_detection_results and self.result_producer:
            self._send_detection_results(boxes, scores, class_ids, timing_info, debug=debug)
        
        # 3. ì¶”ì ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ê²€ì¶œ ê²°ê³¼ë§Œ ë°˜í™˜
        if not self.enable_tracking or len(boxes) == 0:
            return [], timing_info
        
        # 4. DeepSort í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        detections = []
        for box, score, class_id in zip(boxes, scores, class_ids):
            x1, y1, w, h = box.astype(int)
            detections.append(([x1, y1, w, h], float(score), int(class_id)))
        
        # 5. ì¶”ì  ì—…ë°ì´íŠ¸ (embedder ì—†ì´)
        tracks = self.tracker.update_tracks(detections, frame=frame)
        
        # 6. ì‹ ê·œ í™•ì • íŠ¸ë™ ì²˜ë¦¬ ë° Kafka ì „ì†¡
        if self.enable_kafka and self.send_tracking_results and self.track_result_producer:
            self._process_new_tracks(tracks, frame, debug=debug)
        
        return tracks, timing_info

    def _send_detection_results(self, boxes: np.ndarray, scores: np.ndarray, 
                               class_ids: np.ndarray, timing_info: Dict, debug: bool = False) -> None:
        """ê²€ì¶œ ê²°ê³¼ë¥¼ Kafkaë¡œ ì „ì†¡"""
        try:
            # ê²€ì¶œ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ êµ¬ì„±
            detections = []
            for box, score, class_id in zip(boxes, scores, class_ids):
                x1, y1, w, h = box.astype(int)
                class_name = (self.class_names[class_id] if class_id < len(self.class_names) 
                            else f"Class_{class_id}")
                
                detection = {
                    "bbox": [int(x1), int(y1), int(w), int(h)],
                    "confidence": float(score),
                    "class_id": int(class_id),
                    "class_name": class_name
                }
                detections.append(detection)
            
            # ì „ì²´ ë©”ì‹œì§€ êµ¬ì„±
            message = {
                "camera_id": self.camera_id,
                "frame_count": self.frame_count,
                "timestamp": int(time.time() * 1000),
                "detections": detections,
                "timing_info": timing_info,
                "detection_count": len(detections)
            }
            
            # Kafka ì „ì†¡
            result = self.result_producer.send_message(self.camera_id, message)
            
            if result.get('status_code') != 200:
                if debug:
                    print(f"âš ï¸ ê²€ì¶œ ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨: {result.get('error')}")
                
        except Exception as e:
            print(f"âŒ ê²€ì¶œ ê²°ê³¼ Kafka ì „ì†¡ ì˜¤ë¥˜: {e}")

    def _process_new_tracks(self, tracks: List, frame: np.ndarray, debug: bool = False) -> None:
        """ì‹ ê·œ íŠ¸ë™ ì²˜ë¦¬ ë° Kafka ì „ì†¡"""
        for track in tracks:
            if not track.is_confirmed():
                continue
                
            track_id = track.track_id
            if track_id in self.local_id_set:
                continue
            
            try:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                l, t, r, b = track.to_ltrb()
                
                # ê²½ê³„ í™•ì¸
                h, w = frame.shape[:2]
                l = max(0, min(l, w-1))
                t = max(0, min(t, h-1))
                r = max(0, min(r, w-1))
                b = max(0, min(b, h-1))
                
                # ìœ íš¨í•œ í¬ê¸°ì¸ì§€ í™•ì¸
                if r - l < 10 or b - t < 10:
                    continue
                
                # í¬ë¡­ ì¶”ì¶œ
                crop = frame[t:b, l:r]
                
                # íŠ¸ë™ì˜ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
                bbox = [l, t, r-l, b-t]  # [x, y, w, h] í˜•ì‹
                
                # detection ì •ë³´ê°€ ìˆë‹¤ë©´ í™œìš©
                detection = track.get_det() if hasattr(track, 'get_det') else None
                confidence = detection[1] if detection else None
                class_id = detection[2] if detection else None
                class_name = (self.class_names[class_id] if class_id is not None and class_id < len(self.class_names) 
                            else None)
                
                # Kafkaë¡œ ì¶”ì  ê²°ê³¼ ì „ì†¡
                result = self.track_result_producer.send_message(
                    crop=crop,
                    track_id=track_id,
                    bbox=bbox,
                    confidence=confidence,
                    class_name=class_name,
                    encoding='base64'  # ë˜ëŠ” 'binary'
                )
                
                if result.get('status_code') == 200:
                    self.local_id_set.add(track_id)
                    if debug:
                        print(f"âœ… ìƒˆë¡œìš´ íŠ¸ë™ ì „ì†¡ ì™„ë£Œ: ID={track_id}, Class={class_name}")
                else:
                    if debug:
                        print(f"âš ï¸ íŠ¸ë™ ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨: {result.get('error')}")
                    
            except Exception as e:
                if debug:
                    print(f"âŒ íŠ¸ë™ {track_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def infer(self, image: np.ndarray, debug: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict]:
        """ì¶”ë¡  ì‹¤í–‰"""
        try:
            # ì „ì²˜ë¦¬
            start_time = time.time()
            input_tensor, scale, pad_x, pad_y = self.preprocess(image)
            preprocess_time = time.time() - start_time
            
            # GPU ì¶”ë¡ 
            start_time = time.time()
            self._run_inference(input_tensor)
            inference_time = time.time() - start_time
            
            # í›„ì²˜ë¦¬
            start_time = time.time()
            output_data = [output['host'].reshape(output['shape']) for output in self.outputs]
            boxes, scores, class_ids = self.postprocess(output_data, scale, pad_x, pad_y, debug)
            postprocess_time = time.time() - start_time
            
            timing_info = {
                'preprocess': preprocess_time * 1000,  # ms ë‹¨ìœ„ë¡œ ë³€í™˜
                'inference': inference_time * 1000,
                'postprocess': postprocess_time * 1000,
                'total': (preprocess_time + inference_time + postprocess_time) * 1000
            }
            
            return boxes, scores, class_ids, timing_info
            
        except Exception as e:
            print(f"âŒ ì¶”ë¡  ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return np.array([]), np.array([]), np.array([]), {}
    def infer(self, image, debug=False):
        """ì¶”ë¡  ì‹¤í–‰"""
        # ì „ì²˜ë¦¬
        start_time = time.time()
        input_tensor, scale, pad_x, pad_y = self.preprocess(image)
        preprocess_time = time.time() - start_time
        
        if debug:
            print(f"ğŸ” ì¶”ë¡  ë””ë²„ê·¸:")
            print(f"   - ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            print(f"   - ì „ì²˜ë¦¬ëœ í…ì„œ í¬ê¸°: {input_tensor.shape}")
            print(f"   - ìŠ¤ì¼€ì¼: {scale:.3f}, íŒ¨ë”©: ({pad_x}, {pad_y})")
        
        # GPUë¡œ ë°ì´í„° ë³µì‚¬
        start_time = time.time()
        np.copyto(self.inputs[0]['host'], input_tensor.ravel())
        cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
        
        # TensorRT ë²„ì „ì— ë”°ë¥¸ ì¶”ë¡  ì‹¤í–‰ (ìµœì í™”ëœ ë²„ì „)
        try:
            # execute_async_v3 ìš°ì„  ì‚¬ìš© (ê°€ì¥ ë¹ ë¦„)
            if hasattr(self.context, 'execute_async_v3'):
                # í…ì„œ ì£¼ì†Œ ì„¤ì •
                self.context.set_tensor_address(self.input_name, self.inputs[0]['device'])
                for output in self.outputs:
                    self.context.set_tensor_address(output['name'], output['device'])
                # ë¹„ë™ê¸° ì‹¤í–‰
                self.context.execute_async_v3(stream_handle=self.stream.handle)
            else:
                # í´ë°±: execute_v2 ì‚¬ìš© (ë™ê¸°)
                self.context.execute_v2(bindings=self.bindings)
        except Exception as e:
            print(f"ì¶”ë¡  ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            # ìµœì¢… í´ë°±
            self.context.execute_v2(bindings=self.bindings)
        
        # ê²°ê³¼ë¥¼ CPUë¡œ ë³µì‚¬
        for output in self.outputs:
            cuda.memcpy_dtoh_async(output['host'], output['device'], self.stream)
        
        self.stream.synchronize()
        inference_time = time.time() - start_time
        
        # í›„ì²˜ë¦¬
        start_time = time.time()
        output_data = [output['host'].reshape(output['shape']) for output in self.outputs]
        
        if debug:
            print(f"   - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.1f}ms")
            for i, data in enumerate(output_data):
                print(f"   - ì¶œë ¥ {i} í†µê³„: min={np.min(data):.3f}, max={np.max(data):.3f}, mean={np.mean(data):.3f}")
        
        boxes, scores, class_ids = self.postprocess(output_data, scale, pad_x, pad_y, debug)
        postprocess_time = time.time() - start_time
        
        return boxes, scores, class_ids, {
            'preprocess': preprocess_time,
            'inference': inference_time,
            'postprocess': postprocess_time,
            'total': preprocess_time + inference_time + postprocess_time
        }
    def preprocess(self, image: np.ndarray) -> Tuple[np.ndarray, float, int, int]:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        input_h, input_w = self.input_shape[2], self.input_shape[3]
        img_h, img_w = image.shape[:2]
        
        # ìŠ¤ì¼€ì¼ ê³„ì‚°
        scale = min(input_w / img_w, input_h / img_h)
        new_w, new_h = int(img_w * scale), int(img_h * scale)
        
        # ë¦¬ì‚¬ì´ì¦ˆ ë° íŒ¨ë”©
        resized = cv2.resize(image, (new_w, new_h))
        padded = np.full((input_h, input_w, 3), self.DEFAULT_PADDING_COLOR, dtype=np.uint8)
        
        # ì¤‘ì•™ ë°°ì¹˜
        pad_x = (input_w - new_w) // 2
        pad_y = (input_h - new_h) // 2
        padded[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized
        
        # ì •ê·œí™” ë° ì°¨ì› ë³€ê²½
        input_tensor = padded.astype(np.float32) / self.NORMALIZATION_FACTOR
        input_tensor = np.transpose(input_tensor, (2, 0, 1))
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor, scale, pad_x, pad_y

    def postprocess(self, outputs: List[np.ndarray], scale: float, 
                   pad_x: int, pad_y: int, debug: bool = False) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """í›„ì²˜ë¦¬"""
        if debug:
            print(f"ğŸ” í›„ì²˜ë¦¬ ë””ë²„ê·¸: ì¶œë ¥ ê°œìˆ˜: {len(outputs)}")
        
        output = outputs[0]
        
        # í˜•íƒœ ì •ê·œí™”
        if len(output.shape) == 3:
            output = output[0]
            if output.shape[0] < output.shape[1]:
                output = output.T
        
        boxes, scores, class_ids = self._parse_detections(output, scale, pad_x, pad_y, debug)
        
        if len(boxes) == 0:
            return np.array([]), np.array([]), np.array([])
        
        # NMS ì ìš©
        boxes_array = np.array(boxes)
        scores_array = np.array(scores)
        class_ids_array = np.array(class_ids)
        
        indices = cv2.dnn.NMSBoxes(boxes, scores, self.conf_threshold, self.iou_threshold)
        
        if len(indices) > 0:
            if isinstance(indices, tuple):
                indices = indices[0] if len(indices) > 0 else []
            if len(indices) > 0:
                indices = indices.flatten() if hasattr(indices, 'flatten') else indices
                return boxes_array[indices], scores_array[indices], class_ids_array[indices]
        
        return np.array([]), np.array([]), np.array([])

    def _parse_detections(self, output: np.ndarray, scale: float, 
                         pad_x: int, pad_y: int, debug: bool) -> Tuple[List, List, List]:
        """ê²€ì¶œ ê²°ê³¼ íŒŒì‹±"""
        boxes = []
        scores = []
        class_ids = []
        
        for i, detection in enumerate(output):
            x_center, y_center, width, height = detection[:4]
            class_confs = detection[4:]
            
            max_conf = np.max(class_confs)
            class_id = np.argmax(class_confs)
            
            if debug and i < 5:
                print(f"   - ê²€ì¶œ {i}: conf={max_conf:.3f}, class={class_id}")
            
            if max_conf > self.conf_threshold:
                # ì¢Œí‘œ ë³€í™˜
                x_center = (x_center - pad_x) / scale
                y_center = (y_center - pad_y) / scale
                width = width / scale
                height = height / scale
                
                x1 = x_center - width / 2
                y1 = y_center - height / 2
                
                boxes.append([x1, y1, width, height])
                scores.append(float(max_conf))
                class_ids.append(int(class_id))
        
        return boxes, scores, class_ids

    def _allocate_buffers(self):
        """GPU ë©”ëª¨ë¦¬ í• ë‹¹"""
        inputs = []
        outputs = []
        bindings = []
        stream = cuda.Stream()
        
        # TensorRT ë²„ì „ì— ë”°ë¥¸ ì²˜ë¦¬
        if hasattr(self.engine, 'num_io_tensors'):
            # TensorRT 8.5+ ìƒˆë¡œìš´ API
            for i in range(self.engine.num_io_tensors):
                tensor_name = self.engine.get_tensor_name(i)
                dtype = trt.nptype(self.engine.get_tensor_dtype(tensor_name))
                shape = self.context.get_tensor_shape(tensor_name)
                size = trt.volume(shape)
                
                # GPU ë©”ëª¨ë¦¬ í• ë‹¹
                host_mem = cuda.pagelocked_empty(size, dtype)
                device_mem = cuda.mem_alloc(host_mem.nbytes)
                bindings.append(int(device_mem))
                
                if self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:
                    self.input_shape = shape
                    self.input_name = tensor_name
                    inputs.append({'host': host_mem, 'device': device_mem, 'name': tensor_name})
                else:
                    self.output_name = tensor_name
                    outputs.append({'host': host_mem, 'device': device_mem, 'shape': shape, 'name': tensor_name})
        else:
            # TensorRT 7.x/8.x ì´ì „ API
            for binding in self.engine:
                dtype = trt.nptype(self.engine.get_binding_dtype(binding))
                shape = self.context.get_binding_shape(binding)
                size = trt.volume(shape)
                
                # GPU ë©”ëª¨ë¦¬ í• ë‹¹
                host_mem = cuda.pagelocked_empty(size, dtype)
                device_mem = cuda.mem_alloc(host_mem.nbytes)
                bindings.append(int(device_mem))
                
                if self.engine.binding_is_input(binding):
                    self.input_shape = shape
                    self.input_name = binding
                    inputs.append({'host': host_mem, 'device': device_mem, 'name': binding})
                else:
                    self.output_name = binding
                    outputs.append({'host': host_mem, 'device': device_mem, 'shape': shape, 'name': binding})
        
        return inputs, outputs, bindings, stream
    

    def _run_inference(self, input_tensor: np.ndarray) -> None:
        """ğŸ”¥ ì•ˆì •ì ì¸ GPU ì¶”ë¡  ì‹¤í–‰"""
        # GPUë¡œ ë°ì´í„° ë³µì‚¬
        np.copyto(self.inputs[0]['host'], input_tensor.ravel())
        cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
        
        # ì„ íƒëœ ì‹¤í–‰ ë©”ì„œë“œì— ë”°ë¼ ì¶”ë¡  ì‹¤í–‰
        try:
            if self.execution_method == "execute_v2":
                success = self.context.execute_v2(bindings=self.bindings)
                if not success:
                    raise RuntimeError("execute_v2 ì‹¤íŒ¨")
            
            elif self.execution_method == "execute":
                batch_size = 1
                success = self.context.execute(batch_size=batch_size, bindings=self.bindings)
                if not success:
                    raise RuntimeError("execute ì‹¤íŒ¨")
            
            elif self.execution_method == "execute_async_v2":
                success = self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
                if not success:
                    raise RuntimeError("execute_async_v2 ì‹¤íŒ¨")
            
            elif self.execution_method == "execute_async":
                batch_size = 1
                success = self.context.execute_async(batch_size=batch_size, bindings=self.bindings, stream_handle=self.stream.handle)
                if not success:
                    raise RuntimeError("execute_async ì‹¤íŒ¨")
            
            else:
                raise RuntimeError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‹¤í–‰ ë©”ì„œë“œ: {self.execution_method}")
        
        except Exception as e:
            print(f"âŒ {self.execution_method} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            # í´ë°±: execute_v2 ì‹œë„
            try:
                print("   ğŸ”„ execute_v2ë¡œ í´ë°± ì‹œë„...")
                success = self.context.execute_v2(bindings=self.bindings)
                if not success:
                    raise RuntimeError("í´ë°± execute_v2ë„ ì‹¤íŒ¨")
            except Exception as fallback_e:
                print(f"   âŒ í´ë°±ë„ ì‹¤íŒ¨: {fallback_e}")
                raise e  # ì›ë³¸ ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë°œìƒ
        
        # ê²°ê³¼ë¥¼ CPUë¡œ ë³µì‚¬
        for output in self.outputs:
            cuda.memcpy_dtoh_async(output['host'], output['device'], self.stream)
        
        self.stream.synchronize()

    def _print_engine_info(self) -> None:
        """ì—”ì§„ ì •ë³´ ì¶œë ¥"""
        print(f"ğŸ”§ TensorRT ì—”ì§„ ì •ë³´:")
        print(f"   - TensorRT ë²„ì „: {trt.__version__}")
        print(f"   - ì…ë ¥ í¬ê¸°: {self.input_shape}")
        print(f"   - í´ë˜ìŠ¤ ìˆ˜: {len(self.class_names)}")
        print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold}")
        print(f"   - IoU ì„ê³„ê°’: {self.iou_threshold}")

    def extract_crop_from_frame(self, frame: np.ndarray, bbox: List[int]) -> str:
        """í”„ë ˆì„ì—ì„œ crop ì¶”ì¶œí•˜ì—¬ base64ë¡œ ì¸ì½”ë”©"""
        try:
            x, y, w, h = bbox
            crop = frame[y:y+h, x:x+w]
            
            # PIL Imageë¡œ ë³€í™˜
            crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
            
            # base64 ì¸ì½”ë”©
            buffer = io.BytesIO()
            crop_pil.save(buffer, format='JPEG')
            crop_b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return crop_b64
        except Exception as e:
            print(f"âŒ Crop ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def draw_detections(self, image: np.ndarray, boxes: np.ndarray, 
                       scores: np.ndarray, class_ids: np.ndarray, 
                       debug: bool = False) -> np.ndarray:
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        if len(boxes) == 0:
            return image
        
        result_image = image.copy()
        img_h, img_w = image.shape[:2]
        
        for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
            try:
                x1, y1, w, h = box.astype(int)
                x2, y2 = x1 + w, y1 + h
                
                # ê²½ê³„ í™•ì¸
                x1 = max(0, min(x1, img_w - 1))
                y1 = max(0, min(y1, img_h - 1))
                x2 = max(0, min(x2, img_w - 1))
                y2 = max(0, min(y2, img_h - 1))
                
                # ìµœì†Œ í¬ê¸° í™•ì¸
                if x2 - x1 < 5 or y2 - y1 < 5:
                    continue
                
                # ê·¸ë¦¬ê¸°
                self._draw_single_detection(result_image, x1, y1, x2, y2, score, class_id)
                
            except Exception as e:
                if debug:
                    print(f"âš ï¸ ë°•ìŠ¤ {i} ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
                continue
        
        return result_image

    def _draw_single_detection(self, image: np.ndarray, x1: int, y1: int, x2: int, y2: int, 
                              score: float, class_id: int) -> None:
        """ë‹¨ì¼ ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°"""
        class_name = (self.class_names[class_id] if class_id < len(self.class_names) 
                     else f"Class_{class_id}")
        color = tuple(map(int, self.colors[class_id % len(self.colors)]))
        
        # ë°”ìš´ë”© ë°•ìŠ¤
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)
        
        # ë¼ë²¨
        label = f"{class_name}: {score:.2f}"
        (text_w, text_h), baseline = cv2.getTextSize(
            label, self.DEFAULT_FONT, self.DEFAULT_FONT_SCALE, self.DEFAULT_THICKNESS)
        
        # ë°°ê²½
        bg_x1 = x1
        bg_y1 = max(0, y1 - text_h - baseline - 10)
        bg_x2 = min(image.shape[1], x1 + text_w + 10)
        bg_y2 = y1
        
        cv2.rectangle(image, (bg_x1, bg_y1), (bg_x2, bg_y2), color, -1)
        
        # í…ìŠ¤íŠ¸
        cv2.putText(image, label, (x1 + 5, y1 - 5), 
                   self.DEFAULT_FONT, self.DEFAULT_FONT_SCALE, 
                   (255, 255, 255), self.DEFAULT_THICKNESS)

    def get_statistics(self) -> Dict:
        """í˜„ì¬ ìƒíƒœ í†µê³„ ë°˜í™˜"""
        return {
            "camera_id": self.camera_id,
            "frame_count": self.frame_count,
            "active_tracks": len(self.local_id_set),
            "kafka_enabled": self.enable_kafka,
            "tracking_enabled": self.enable_tracking,
            "detection_results_sending": self.send_detection_results,
            "tracking_results_sending": self.send_tracking_results,
            "execution_method": getattr(self, 'execution_method', 'unknown')
        }

    def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            # CUDA ìŠ¤íŠ¸ë¦¼ ë™ê¸°í™”
            if hasattr(self, 'stream'):
                self.stream.synchronize()
            
            # Kafka Producer ì¢…ë£Œ
            if self.result_producer:
                self.result_producer.close()
                print("âœ… DetectedResultProducer ì¢…ë£Œ ì™„ë£Œ")
            
            if self.track_result_producer:
                self.track_result_producer.close()
                print("âœ… TrackResultProducer ì¢…ë£Œ ì™„ë£Œ")
            
            print("âœ… DetectorAndTracker ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def __del__(self):
        """ì†Œë©¸ì"""
        self.cleanup()


# ì‚¬ìš© ì˜ˆì‹œ
def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    try:
        # DetectorAndTracker ì´ˆê¸°í™”
        detector = DetectorAndTracker(
            camera_id="camera_001",
            engine_path="/home/hiperwall/Ai_modules/Ai/poc/yolo_engine/yolo11m_fp16.engine",
            conf_threshold=0.25,
            iou_threshold=0.45,
            enable_kafka=True,
            enable_tracking=True,
            send_detection_results=True,
            send_tracking_results=True
        )
        
        # ë”ë¯¸ í”„ë ˆì„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # ê²€ì¶œ ë° ì¶”ì  ì‹¤í–‰
        tracks, timing = detector.detect_and_track(test_frame, debug=True)
        
        print(f"ğŸ“Š í†µê³„ ì •ë³´: {detector.get_statistics()}")
        print(f"â±ï¸ íƒ€ì´ë° ì •ë³´: {timing}")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    finally:
        if 'detector' in locals():
            detector.cleanup()

if __name__ == "__main__":
    main()