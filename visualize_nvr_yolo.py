import cv2
import numpy as np
import torch
import gc
import time
import sys
import os

# CUDA ê´€ë ¨ imports
try:
    import pycuda.driver as cuda
    import pycuda.autoinit  # ì¤‘ìš”: CUDA ì»¨í…ìŠ¤íŠ¸ ìë™ ì´ˆê¸°í™”
    PYCUDA_AVAILABLE = True
except ImportError:
    print("âš ï¸  PyCUDA not available, using PyTorch CUDA only")
    PYCUDA_AVAILABLE = False

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('/home/hiperwall/Ai_modules/new/poc')

from poc.tracking_module.tracker import DetectorTracker, initialize_cuda_context
from poc.nvr_util.nvr_client import NVRClient
from poc.nvr_util.exceptions import NVRConnectionError, NVRRecieveError

def initialize_cuda():
    """CUDA í™˜ê²½ ì´ˆê¸°í™” ë° ë©”ëª¨ë¦¬ ì •ë¦¬"""
    print("ğŸ”§ Initializing CUDA environment...")
    
    try:
        # PyTorch CUDA ì´ˆê¸°í™” ë° ì •ë¦¬
        if torch.cuda.is_available():
            print(f"ğŸ“± CUDA devices available: {torch.cuda.device_count()}")
            print(f"ğŸ“± Current device: {torch.cuda.current_device()}")
            print(f"ğŸ“± Device name: {torch.cuda.get_device_name()}")
            
            # CUDA ìºì‹œ ì •ë¦¬
            torch.cuda.empty_cache()
            gc.collect()
            
            # CUDA ë””ë°”ì´ìŠ¤ ì„¤ì •
            torch.cuda.set_device(0)
            
            # CUDA ì»¨í…ìŠ¤íŠ¸ ì›Œë°ì—…
            warmup_tensor = torch.zeros(1).cuda()
            del warmup_tensor
            torch.cuda.synchronize()
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
            memory_allocated = torch.cuda.memory_allocated() / 1024**2
            memory_reserved = torch.cuda.memory_reserved() / 1024**2
            print(f"ğŸ”‹ GPU Memory - Allocated: {memory_allocated:.1f}MB, Reserved: {memory_reserved:.1f}MB")
            
        else:
            print("âŒ CUDA not available!")
            return False
            
        # PyCUDA ì´ˆê¸°í™” (ê°€ëŠ¥í•œ ê²½ìš°)
        if PYCUDA_AVAILABLE:
            try:
                cuda_context = initialize_cuda_context()
                if cuda_context:
                    print(f"ğŸ”§ PyCUDA context initialized successfully")
            except Exception as e:
                print(f"âš ï¸  PyCUDA initialization warning: {e}")
        
        print("âœ… CUDA environment initialized successfully")
        return True
        
    except Exception as e:
        print(f"âŒ CUDA initialization failed: {e}")
        return False

def cleanup_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        gc.collect()

def select_camera_channel(nvr_client):
    """ì‚¬ìš©í•  ì¹´ë©”ë¼ ì±„ë„ ì„ íƒ"""
    if not nvr_client.NVRChannelList:
        raise Exception("No camera channels available")
    
    if len(nvr_client.NVRChannelList) == 1:
        return nvr_client.NVRChannelList[0]
    
    print("ğŸ“¹ Available cameras:")
    for i, channel in enumerate(nvr_client.NVRChannelList):
        print(f"  {i}: Camera {channel.camera_id} ({channel.camera_ip})")
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ì¹´ë©”ë¼ ì„ íƒ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‚¬ìš©ì ì…ë ¥ ë°›ì„ ìˆ˜ ìˆìŒ)
    selected_index = 0
    return nvr_client.NVRChannelList[selected_index]
    """í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"""
    print("ğŸ”§ Setting up environment variables...")
    
    # CUDA í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    os.environ['TORCH_USE_CUDA_DSA'] = '1'
    
    # TensorRT ë¡œê¹… ë ˆë²¨ ì„¤ì • (ì„ íƒì‚¬í•­)
    os.environ['TRT_LOGGER_VERBOSITY'] = 'WARNING'
    
    print("âœ… Environment variables set")

def main():
    print("ğŸš€ Starting NVR YOLO Visualization with GPU optimization...")
    
    # í™˜ê²½ ì„¤ì •
    
    # CUDA ì´ˆê¸°í™”
    if not initialize_cuda():
        print("âŒ Failed to initialize CUDA. Exiting...")
        return
    
    try:
        # DetectorTracker ì´ˆê¸°í™” ì „ ë©”ëª¨ë¦¬ ì •ë¦¬
        cleanup_gpu_memory()
        print("ğŸš€ Initializing DetectorTracker...")
        
        # DetectorTracker ì´ˆê¸°í™”
        engine_path = "yolo11m_fp16.engine"
        detector_tracker = DetectorTracker(engine_path=engine_path)
        
        print("ğŸ“Š Engine Info:", detector_tracker.get_engine_info())
        
        # NVR í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        print("ğŸ“¡ Connecting to NVR...")
        nvr_client = NVRClient()
        
        # ì¹´ë©”ë¼ ì±„ë„ ì„ íƒ
        channel = select_camera_channel(nvr_client)
        print(f"ğŸ“¹ Selected camera: {channel.camera_id} ({channel.camera_ip})")
        
        # NVR ì±„ë„ ì—°ê²°
        try:
            channel.connect()
            print(f"âœ… Connected to camera: {channel.camera_id}")
            print(f"ğŸ“Š Camera info - Resolution: {channel.width}x{channel.height}, FPS: {channel.fps:.1f}")
        except NVRConnectionError as e:
            raise Exception(f"NVR connection failed: {e}")
        except Exception as e:
            raise Exception(f"Failed to connect to camera: {e}")
        
        print("ğŸ¥ Starting video processing... Press 'q' to quit")
        
        frame_count = 0
        start_time = time.time()
        connection_retry_count = 0
        max_retries = 5
        
        try:
            while True:
                # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (NVR ë°©ì‹)
                try:
                    ret, frame = channel.cap.read()
                    if not ret or frame is None:
                        print("âš ï¸  No frame received, attempting reconnection...")
                        
                        # ì¬ì—°ê²° ì‹œë„
                        if connection_retry_count < max_retries:
                            try:
                                channel.disconnect()
                                time.sleep(1)
                                channel.connect()
                                connection_retry_count += 1
                                print(f"ğŸ”„ Reconnection attempt {connection_retry_count}/{max_retries}")
                                continue
                            except Exception as reconnect_error:
                                print(f"âŒ Reconnection failed: {reconnect_error}")
                                connection_retry_count += 1
                                time.sleep(2)
                                if connection_retry_count >= max_retries:
                                    raise Exception("Max reconnection attempts reached")
                                continue
                        else:
                            raise Exception("Max reconnection attempts reached")
                            
                    # ì—°ê²° ì„±ê³µ ì‹œ ì¬ì‹œë„ ì¹´ìš´í„° ë¦¬ì…‹
                    connection_retry_count = 0
                    
                except NVRRecieveError as nvr_error:
                    print(f"âš ï¸  NVR receive error: {nvr_error}")
                    time.sleep(0.1)
                    continue
                except Exception as frame_error:
                    print(f"âš ï¸  Frame read error: {frame_error}")
                    time.sleep(0.1)
                    continue
                
                frame_count += 1
                
                # ì£¼ê¸°ì ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (100í”„ë ˆì„ë§ˆë‹¤)
                if frame_count % 100 == 0:
                    cleanup_gpu_memory()
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
                    if torch.cuda.is_available():
                        memory_allocated = torch.cuda.memory_allocated() / 1024**2
                        memory_reserved = torch.cuda.memory_reserved() / 1024**2
                        elapsed_time = time.time() - start_time
                        fps = frame_count / elapsed_time
                        print(f"ğŸ“Š Frame: {frame_count}, FPS: {fps:.1f}, "
                              f"GPU Memory: {memory_allocated:.1f}MB/{memory_reserved:.1f}MB")
                
                try:
                    # YOLO ì¶”ë¡  ì‹¤í–‰
                    results = detector_tracker.detect_and_track(frame)
                    
                    # ê²°ê³¼ ì‹œê°í™”
                    annotated_frame = detector_tracker.visualize_results(frame, results)
                    
                    # ê²€ì¶œëœ ê°ì²´ ìˆ˜ í‘œì‹œ (ì£¼ê¸°ì ìœ¼ë¡œ)
                    if frame_count % 100 == 0 and results:
                        print(f"ğŸ¯ Detected {len(results)} person(s) at frame {frame_count}")
                    
                    # í”„ë ˆì„ í‘œì‹œ
                    cv2.imshow('NVR YOLO Detection', annotated_frame)
                    
                except Exception as inference_error:
                    print(f"âš ï¸  Inference error at frame {frame_count}: {inference_error}")
                    print(f"ğŸ” Error type: {type(inference_error).__name__}")
                    
                    # ì¶”ë¡  ì‹¤íŒ¨ ì‹œ ì›ë³¸ í”„ë ˆì„ í‘œì‹œ
                    cv2.imshow('NVR YOLO Detection', frame)
                    
                    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„
                    cleanup_gpu_memory()
                    time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°
                
                # í‚¤ ì…ë ¥ í™•ì¸
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ›‘ Quit signal received")
                    break
                    
        except KeyboardInterrupt:
            print("\nğŸ›‘ Interrupted by user")
            
    except Exception as e:
        print(f"âŒ Error during execution: {e}")
        print("ğŸ”§ Attempting GPU memory cleanup...")
        cleanup_gpu_memory()
        
    finally:
        print("ğŸ§¹ Cleaning up resources...")
        
        # NVR ì—°ê²° í•´ì œ
        try:
            if 'channel' in locals():
                channel.disconnect()
                print("ğŸ“¡ NVR channel disconnected")
        except Exception as e:
            print(f"âš ï¸  NVR disconnect warning: {e}")
        
        # ìµœì¢… ì •ë¦¬
        cleanup_gpu_memory()
        
        # OpenCV ìœˆë„ìš° ì •ë¦¬
        cv2.destroyAllWindows()
        
        # ì¶”ê°€ ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        print("âœ… Cleanup completed")
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1024**2
            memory_reserved = torch.cuda.memory_reserved() / 1024**2
            print(f"ğŸ”‹ Final GPU Memory - Allocated: {memory_allocated:.1f}MB, Reserved: {memory_reserved:.1f}MB")

if __name__ == "__main__":
    main()